\section{Model Comparison}

% \subsection{Leituras Recomendadas}
% \begin{frame}{Comparação de Modelos - Leituras Recomendadas}
% 	\begin{vfilleditems}
% 		\item \textcite{gelman2013bayesian} - Capítulo 7: Evaluating, comparing, and expanding models
% 		\item \textcite{gelman2020regression} - Capítulo 11, Seção 11.8: Cross validation
% 		\item \textcite{mcelreath2020statistical} - Capítulo 7, Seção 7.5: Model comparison
% 		\item \textcite{vehtariPracticalBayesianModel2015}
% 		\item Tutorial do \texttt{loo} de \textcite{loo}
% 		\item \textcite{storopoli2021estatisticabayesianaR} - Comparação de Modelos
% 		\item \textcite{spiegelhalter2002bayesian}
% 		\item \textcite{van2005dic}
% 		\item \textcite{watanabe2010asymptotic}
% 		\item \textcite{gelfand1996model}
% 		\item \textcite{watanabe2010asymptotic}
% 		\item \textcite{geisser1979predictive}
% 	\end{vfilleditems}
% \end{frame}

% \subsection{Por quê Comparar Modelos?}
% \begin{frame}{Por quê Comparar Modelos?}
% 	Depois de estimarmos um modelo Bayesiano,
% 	muitas vezes queremos medir sua precisão preditiva, por si só ou para
% 	fins de comparação, seleção ou cálculo de média do modelo \parencite{geisser1979predictive}.
% \end{frame}

% \begin{frame}{Mas, e as Verificações Preditivas da Posterior?}
% 	É uma maneira subjetiva e arbitrária de analisarmos e compararmos modelos
% 	entre si usando sua precisão preditiva.
% 	\vfill
% 	Há uma maneira objetiva de compararmos modelos Bayesianos com uma
% 	métrica robusta que nos ajude a selecionar qual o melhor modelo dentre o rol
% 	de modelos candidatos.
% 	\vfill
% 	Ter uma maneira objetiva de comparar modelos e escolher o melhor dentre eles
% 	é muito importante pois no \textit{workflow} Bayesiano geralmente temos diversas
% 	iterações entre \textit{prioris} e funções de verossimilhança o que ocasiona na
% 	criação de diversos modelos diferentes \parencite{gelmanBayesianWorkflow2020}.
% \end{frame}

% \subsection{Técnicas de Comparação de Modelos}
% \begin{frame}{Técnicas de Comparação de Modelos}
% 	Temos diversas técnicas de comparação de modelos que usam a precisão preditiva,
% 	sendo as principais:
% 	\begin{vfilleditems}
% 		\item \textit{Leave-one-out cross-validation} (LOO)
% 		\parencite{vehtariPracticalBayesianModel2015}
% 		\item \textit{Deviance Information Criterion} (DIC)
% 		\parencite{spiegelhalter2002bayesian},  mas sabe-se que tem alguns problemas,
% 		que surgem em parte por não ser totalmente Bayesiano,
% 		pois se baseia em uma estimativa pontual \parencite{van2005dic}
% 		\item \textit{Widely Applicable Information Criteria} (WAIC)
% 		\parencite{watanabe2010asymptotic}, totalmente Bayesiano no sentido
% 		de que usa toda a distribuição posterior, e é assintoticamente igual ao
% 		LOO \parencite{vehtariPracticalBayesianModel2015}
% 	\end{vfilleditems}
% \end{frame}

% \begin{frame}{Interlúdio Histórico}
% 	\small
% 	Antigamente, não havia esse poder computacional e abundância de dados.
% 	Comparação de modelos eram baseados em uma métrica de divergência teórica
% 	oriunda da entropia da teoria da informação:
% 	$$
% 		H(p) = - \operatorname{E}\log(p_i) = -\sum^N_{i=1} p_i \log(p_i)
% 	$$
% 	\small
% 	Calculamos a divergência\footnote{\textit{divergence}} multiplicando por
% 	$-2$\footnote{razões históricas},
% 	então menores valores são melhores:
% 	$$
% 		D(y, \boldsymbol{\theta}) = -2 \cdot \underbrace{\sum^N_{i=1} \log \frac{1}{S}\sum^S_{s=1} P(y_i \mid \boldsymbol{\theta}^s)}_{\text{\textit{log pointwise predictive density} -- lppd}}
% 	$$
% 	\footnotesize
% 	onde $N$ é o tamanho da amostra e $S$ é o número de amostras simuladas da posterior.
% \end{frame}

% \begin{frame}{Interlúdio Histórico -- AIC \parencite{akaike1998information}}
% 	$$\text{AIC} = D(y, \boldsymbol{\theta}) + 2k = -2 \text{lppd}_{\text{mle}} + 2k$$
% 	onde $k$ é o número de parâmetros livres do modelo e $\text{lppd}_{\text{mle}}$ é
% 	a estimação de máxima verossimilhança (MLE) da lppd.
% 	\vfill
% 	AIC é uma aproximação que somente pode ser confiável quando:
% 	\begin{vfilleditems}
% 		\item As \textit{prioris} são uniformes (\textit{flat priors}) ou dominadas totalmente pela função de verossimilhança
% 		\item A posterior é aproximadamente uma distribuição Gaussiana/normal multivariada
% 		\item O tamanho da amostra $N$ é muito maior que número de parâmetros livres $k$: $N \gg k$
% 	\end{vfilleditems}
% \end{frame}

% \begin{frame}{Interlúdio Histórico -- DIC \parencite{spiegelhalter2002bayesian}}
% 	Uma generalização do AIC, onde substituímos a estimação de máxima verossimilhança
% 	pela média da posterior e $k$ por uma correção de viés baseada nos dados:
% 	$$
% 		DIC = D(y, \boldsymbol{\theta}) + k_{\text{DIC}} = -2 \text{lppd}_{\text{Bayes}}
% 		+2 \underbrace{\left( \text{lppd}_{\text{Bayes}} - \frac{1}{S} \sum^S_{s=1} \log P(y \mid \boldsymbol{\theta}^s) \right)}_{\text{$k$ corrigido de viés}}
% 	$$
% 	DIC remove a restrição das \textit{prioris} uniformes de AIC, mas mesmo assim
% 	mantém os presupostos da posterior ser uma distribuição Gaussiana/normal multivariada
% 	e que $N \gg k$
% \end{frame}

% \subsubsection{Precisão Preditiva}
% \begin{frame}{Precisão Preditiva}
% 	Com o poder computacional que temos hoje não precisamos de aproximações\footnote{AIC, DIC etc.}.
% 	\vfill
% 	Podemos discutir métricas objetivas de \textbf{precisão preditiva}.
% 	\vfill
% 	Mas antes vamos definir o que é precisão preditiva.
% \end{frame}

% \begin{frame}{Precisão Preditiva}
% 	\begin{defn}[Precisão Preditiva]
% 		Bayesianos mensuram precisão preditiva usando simulações da distribuição posterior
% 		$\tilde{y}$ do modelo. Para isso temos a distribuição preditiva posterior
% 		(\textit{predictive posterior distribution}):
% 		$$
% 			p(\tilde{y} \mid y) = \int p(\tilde{y}_i \mid \theta) p(\theta \mid y) d \theta
% 		$$
% 		\small
% 		Onde $p(\theta \mid y)$ é a distribuição posterior do modelo\footnote{aquela
% 			que o \texttt{rstanarm} e \texttt{brms} estima para nós}.
% 		A fórmula acima significa que calculamos a integral de toda a
% 		probabilidade conjunta da distribuição posterior preditiva com a
% 		distribuição posterior do nosso modelo
% 		\normalsize
% 		Quanto \textbf{maior} a distribuição preditiva posterior
% 		$p(\tilde{y} \mid y)$ \textbf{melhor} será a precisão preditiva do modelo.
% 	\end{defn}
% \end{frame}

% \begin{frame}{Precisão Preditiva}
% 	Para mantermos comparabilidade entre amostras, calculamos a
% 	esperança dessa medida\footnote{do inglês \textit{expectation} que pode ser
% 		também interpretada como a média ponderada} para cada uma das $N$ observações
% 	da amostra:

% 	$$
% 		\operatorname{elpd} = \sum_{i=1}^N \int p_t(\tilde{y}_i) \log p(\tilde{y}_i \mid y) d \tilde{y}
% 	$$

% 	onde $\operatorname{elpd}$ é esperança do log da densidade preditiva pontual
% 	(\textit{expected log pointwise predictive density}) e
% 	$p_t(\tilde{y}_i)$ é a distribuição representando o verdadeiro processo
% 	generativo dos dados para $\tilde{y}_i$.
% 	Os $p_t(\tilde{y}_i)$ são desconhecidos e geralmente usamos validação
% 	cruzada\footnote{\textit{Cross Validation}} ou aproximação para
% 	a estimação da $\operatorname{elpd}$.
% \end{frame}

% \subsubsection{\textit{Leave-One-Out Cross-Validation} (LOO)}
% \begin{frame}{\textit{Leave-One-Out Cross-Validation} (LOO)}
% 	Podemos calcular a $\operatorname{elpd}$ usando LOO
% 	\parencite{vehtariPracticalBayesianModel2015}:
% 	$$
% 		\operatorname{elpd}_{\text{loo}} = \sum_{i=1}^N \log p(y_i \mid y_{-i})
% 	$$
% 	onde
% 	$$
% 		p(y_i \mid y_{-i}) = \int p(y_i \mid \theta) p(\theta \mid y_{-i}) d \theta
% 	$$
% 	que é a densidade preditiva com uma observação a menos condicionada nos
% 	dados sem a observação $i$ ($y_{-i}$). Quase sempre usamos a aproximação
% 	PSIS-LOO\footnote{mais sobre isso já já...} pela sua robustez e baixo custo
% 	computacional.
% \end{frame}

% \subsubsection{\textit{Widely Applicable Information Criteria} (WAIC)}
% \begin{frame}{\textit{Widely Applicable Information Criteria} (WAIC)}
% 	\footnotesize
% 	WAIC \parencite{watanabe2010asymptotic}, assim como o LOO também é uma
% 	abordagem alternativa para calcularmos a $\operatorname{elpd}$ e é definida como:

% 	$$
% 		\widehat{\operatorname{elpd}}_{\text{waic}} = \widehat{\operatorname{lppd}} - \widehat{p}_{\text{waic}}
% 	$$

% 	onde $\widehat{p}_{\text{waic}}$ é o número estimado efetivo de paramêtros e
% 	calculado com base em:

% 	$$
% 		\widehat{p}_{\text{waic}} = \sum_{i=1}^N \operatorname{var}_{\text{post}} (\log p(y_i \mid \theta))
% 	$$

% 	que conseguimos calcular usando a variância posterior do log da densidade preditiva para cada observação $y_i$:

% 	$$
% 		\widehat{p}_{\text{waic}} = \sum_{i=1}^N V^S_{s=1} (\log p(y_i \mid \theta^s))
% 	$$
% 	onde $V^S_{s=1}$ representa a variância da amostra:

% 	$$
% 		V^S_{s=1} a_s = \frac{1}{S-1} \sum^S_{s=1} (a_s - \bar{a})^2
% 	$$
% \end{frame}

% \subsubsection{\textit{K-fold Cross-Validation} (K-fold CV)}
% \begin{frame}{\textit{K-fold Cross-Validation} (K-fold CV)}
% 	Da mesma maneira que conseguimos cacular a $\operatorname{elpd}$ usando LOO
% 	com $N-1$ partições da amostra podemos também calcular com qualquer número de
% 	partições que quisermos.
% 	\vfill
% 	Tal abordagem é chamada de \textbf{validação cruzada usando $K$ partições}
% 	(\textit{$K$-fold Cross-Validation}, encurtado para \textit{$K$-fold CV}).
% 	\vfill
% 	Ao contrário de LOO, não conseguimos aproximar a
% 	$\operatorname{elpd}$ usando \textit{$K$-fold CV} e precisamos fazer a computação
% 	atual da $\operatorname{elpd}$ sobre $K$ partições que quase sempre envolve
% 	um \textbf{alto custo computacional}.
% \end{frame}

% \subsection{\textit{Pareto Smoothed Importance Sampling} LOO (PSIS-LOO)}
% \begin{frame}{\textit{Pareto Smoothed Importance Sampling} LOO (PSIS-LOO)}
% 	O PSIS usa \textbf{amostragem de importância}\footnote{\textit{importance sampling}},
% 	o que significa apenas que usa a abordagem de pesos de importância.
% 	\vfill
% 	A \textbf{suavização de Pareto} é uma técnica para tornar os pesos de importância
% 	mais confiáveis.
% \end{frame}
% \begin{frame}{Amostragem de Importância (\textit{Importance Sampling})}
% 	Se as $N$ amostras são condicionalmente independentes\footnote{ou seja
% 		são independentes condicionadas aos parâmetros do modelo, que é o pressuposto
% 		básico de qualquer modelo probabilístico Bayesiano} \parencite{gelfand1992model}
% 	podemos avaliar LOO com amostras $\boldsymbol{\theta}^s$ da posterior
% 	$P(\theta \mid y)$ usando \textbf{pesos de importância}:
% 	$$
% 		r_i^s=\frac{1}{P(y_i|\theta^s)} \propto \frac{P(\theta^s|y_{-i})}{P(\theta^s|y)}
% 	$$
% 	Para então conseguirmos \textit{Importance Sampling Leave-One-Out} (IS-LOO):
% 	$$
% 		P(\tilde{y}_i|y_{-i})
% 		\approx
% 		\frac{\sum_{s=1}^S r_i^s P(\tilde{y}_i|\theta^s)}{\sum_{s=1}^S r_i^s}
% 	$$
% \end{frame}

% \begin{frame}{Amostragem de Importância (\textit{Importance Sampling})}
% 	Porém a posterior $P(\theta \mid y)$ geralmente possui baixa variância e caudas
% 	mais curtas que as distribuições LOO $P(\theta \mid y_{-1})$ então se usarmos:
% 	$$
% 		P(\tilde{y}_i|y_{-i}) \approx \frac{\sum_{s=1}^S r_i^s P(\tilde{y}_i|\theta^s)}{\sum_{s=1}^S r_i^s}
% 	$$
% 	podemos gerar instabilidades pois os $r_i$ podem ter variância alta ou até infinita.
% \end{frame}

% \begin{frame}{Amostragem de Importância com Suavização de Pareto \textit{Pareto Smoothed Importance Sampling}}
% 	Podemos aprimorar a estimativa IS-LOO usando uma \textbf{suavização de Pareto}
% 	(\textit{Pareto Smoothed Importance Sampling}) \parencite{vehtariPracticalBayesianModel2015}
% 	\vfill
% 	Quando a cauda da distribuição dos pesos de importância é longa, um uso direto
% 	da amostragem de importância é sensível a um ou alguns valores grandes.
% 	Ajustando uma distribuição de Pareto generalizada à cauda superior dos pesos de
% 	importância, suavizamos esses valores.
% \end{frame}
% \begin{frame}{\textit{Pareto Smoothed Importance Sampling} LOO (PSIS-LOO)}
% 	Por fim temos PSIS-LOO:
% 	$$
% 		\widehat{\operatorname{elpd}}_{\rm psis-loo} =
% 		\sum_{i=1}^n \log
% 		\left(\frac{\sum_{s=1}^S w_i^s P(y_i|\theta^s)}{\sum_{s=1}^Sw_i^s} \right)
% 	$$
% 	onde $w$ é o peso truncado.
% \end{frame}

% \begin{frame}{\textit{Pareto Smoothed Importance Sampling} LOO (PSIS-LOO)}
% 	\small
% 	Usamos o parâmetro estimado de forma $\widehat{k}$ da distribuição de Pareto
% 	dos pesos de importância para avaliar a confiabilidade da estimativa:
% 	\begin{vfilleditems}
% 		\item \small $k < \frac{1}{2}$ a variância dos pesos de importância é finita,
% 		o teorema do limite central se mantém, e a estimativa converge rapidamente
% 		\item \small $\frac{1}{2} < k < 1$ a variância dos pesos de importância é infinitas,
% 		mas a média existe, o teorema do limite central generalizado
% 		para distribuições estáveis se mantém, e a convergência da estimativa é mais
% 		lenta
% 		A variação da estimativa PSIS é finita, mas pode ser grande.
% 		\item \small $k > 1$ a variância e a média da distribuição de pesos de importância não
% 		existe. A variação da estimativa PSIS é finita, mas pode ser grande
% 	\end{vfilleditems}
% 	\vfill
% 	\small
% 	Qualquer valor de $\widehat{k}$ maior que $0.5$ é sinal de alerta mas na prática
% 	ainda há um bom desempenho com $\widehat{k}$ até $0.7$
% \end{frame}

% \subsection{Comparação de Modelos no \texttt{rstarnarm}}
% \begin{frame}[fragile]{Comparação de Modelos no \href{http://mc-stan.org/rstanarm/}{\texttt{rstanarm}}}
% 	\begin{lstlisting}
%     library(loo)

%     loo_1 <- loo(rstanarm_model_1)
%     loo_2 <- loo(rstanarm_model_2)
%     loo_3 <- loo(rstanarm_model_3)

%     loo_compare(loo_1, loo_2, loo_3)
%     \end{lstlisting}
% \end{frame}

% \subsection{Comparação de Modelos no \texttt{brms}}
% \begin{frame}[fragile]{Comparação de Modelos no \href{https://paul-buerkner.github.io/brms/}{\texttt{brms}}}
% 	\begin{lstlisting}
%     library(loo)

%     loo_1 <- loo(brms_model_1)
%     loo_2 <- loo(brms_model_2)
%     loo_3 <- loo(brms_model_3)

%     loo_compare(loo_1, loo_2, loo_3)
%     \end{lstlisting}
% \end{frame}
